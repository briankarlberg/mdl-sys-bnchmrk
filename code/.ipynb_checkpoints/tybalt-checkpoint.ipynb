{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f652de-1cd8-4aa6-9036-55118ab7408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 'r72'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943d81c-78a4-4776-8d50-b83cb8934fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6d5a3-6c04-4c69-81f8-e39f0f9ceefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../data/r72/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebddc8-b3c9-43d8-8273-e387edb023eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_2 = sorted(\n",
    "    glob.glob(\n",
    "        '../data/r72/*'), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc4467-963b-4fec-a9be-7e1b4efebc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Layer\n",
    "from tensorflow.keras import metrics, optimizers\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd53a2b-426b-42bc-b32b-dd26123ab2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE functions\n",
    "def compute_latent(x):\n",
    "    mu, sigma = x\n",
    "    batch = K.shape(mu)[0]\n",
    "    dim = K.shape(mu)[1]\n",
    "    eps = K.random_normal(shape=(batch,dim), mean=0., stddev=1.0 )\n",
    "    return mu + K.exp(sigma/2)*eps\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        reconstruction_loss = original_dim * metrics.binary_crossentropy(\n",
    "            x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded - K.square(z_mean_encoded) - \n",
    "                                K.exp(z_log_var_encoded), axis=-1)\n",
    "        return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        return x\n",
    "    \n",
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta, kappa):\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d6ed0-4f24-4667-870a-78cd189dac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss plot visualization to determine degree of model fitting\n",
    "def plot_loss(loss_dict, cancer, modality, systems, latent_dim, train_file):\n",
    "\n",
    "    # Create a new figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot loss values\n",
    "    plt.plot(loss_dict['vs0'], marker='o', linestyle='-', color='b')\n",
    "\n",
    "    # Add a grid\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title(cancer+' '+modality+' '+systems+' VAE Loss', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Epoch', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "    # Annotation for epochs and latent dimension\n",
    "    plt.annotate('Samples: {}'.format(\n",
    "        len(train_file))+'\\nLatent dim: '+str(\n",
    "        latent_dim)+'\\nRaw features: {}'.format(len(train_file.columns)), \n",
    "                 xy=(0.7, 0.3), xycoords='axes fraction', \n",
    "                 bbox=dict(boxstyle='round, pad=0.5', fc='white', ec='black'),\n",
    "                 fontsize=12)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(#'loss_plots/'+data_type+'_vae_loss.png'\n",
    "               '../results/r72/tybalt/'+cancer+'_'+modality+'_'+\n",
    "                         systems+'_'+str(latent_dim)+'-ltnt-dim_'+\n",
    "                         str(epochs)+'-epchs_loss.png')\n",
    "    # plt.close()  # Close the figure - not for interactive devel / demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1ac35-61bd-46d9-a0fa-dea44bd6423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "for fl_pth in n_2:\n",
    "    print(fl_pth)\n",
    "    cancer = fl_pth.split('_')[0].split('/')[-1]\n",
    "    modality = fl_pth.split('_')[1]\n",
    "    systems = fl_pth.split('_')[2].split('.')[0]\n",
    "    latent_header_prefix = modality[:4]\n",
    "    train_file = pd.read_csv(fl_pth,\n",
    "                        sep = '\\t', index_col = 0)\n",
    "    sys_lbls = train_file.System\n",
    "    cncr_lbls = train_file.Cancer_type\n",
    "    train_file = train_file.iloc[:, 2:]\n",
    "\n",
    "    # Normalize\n",
    "    scaler = MinMaxScaler()\n",
    "    train_file = pd.DataFrame(\n",
    "        scaler.fit_transform(train_file),\n",
    "        columns=train_file.columns,\n",
    "        index=train_file.index)\n",
    "    # break\n",
    "    # Variational auto-encoder, Tybalt\n",
    "    loss_dict = {}\n",
    "    vs_list = ['vs0']\n",
    "    validation_split = vs_list[0]\n",
    "    \n",
    "    features = train_file.columns\n",
    "    \n",
    "    original_dim = len(features)\n",
    "    feature_dim = len(features)\n",
    "    latent_dim = 250\n",
    "    batch_size = 50\n",
    "    \n",
    "    encoder_inputs = keras.Input(shape=(feature_dim,))\n",
    "    z_mean_dense_linear = layers.Dense(\n",
    "        latent_dim, kernel_initializer='glorot_uniform', name=\"encoder_1\")(encoder_inputs)\n",
    "    z_mean_dense_batchnorm = layers.BatchNormalization()(z_mean_dense_linear)\n",
    "    z_mean_encoded = layers.Activation('relu')(z_mean_dense_batchnorm)\n",
    "    \n",
    "    z_log_var_dense_linear = layers.Dense(\n",
    "        latent_dim, kernel_initializer='glorot_uniform', name=\"encoder_2\")(encoder_inputs)\n",
    "    z_log_var_dense_batchnorm = layers.BatchNormalization()(z_log_var_dense_linear)\n",
    "    z_log_var_encoded = layers.Activation('relu')(z_log_var_dense_batchnorm)\n",
    "    \n",
    "    latent_space = layers.Lambda(\n",
    "        compute_latent, output_shape=(\n",
    "            latent_dim,), name=\"latent_space\")([z_mean_encoded, z_log_var_encoded])\n",
    "    \n",
    "    decoder_to_reconstruct = layers.Dense(\n",
    "        feature_dim, kernel_initializer='glorot_uniform', activation='sigmoid')\n",
    "    decoder_outputs = decoder_to_reconstruct(latent_space)\n",
    "    \n",
    "    learning_rate = 0.0005\n",
    "    \n",
    "    kappa = 1\n",
    "    beta = K.variable(0)\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "    vae_layer = CustomVariationalLayer()([encoder_inputs, decoder_outputs])\n",
    "    vae = Model(encoder_inputs, vae_layer)\n",
    "    vae.compile(optimizer=adam, loss=None, loss_weights=[beta])\n",
    "    \n",
    "    history = vae.fit(train_file,\n",
    "                epochs=epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      callbacks=[WarmUpCallback(beta, kappa)],\n",
    "                      verbose=1)\n",
    "    loss_dict[validation_split] = history.history['loss']\n",
    "    \n",
    "    encoder = Model(encoder_inputs, z_mean_encoded)\n",
    "    latent_object = pd.DataFrame(\n",
    "        encoder.predict(train_file),\n",
    "        index=train_file.index\n",
    "    )\n",
    "    latent_object.index.name = train_file.index.name\n",
    "    # break\n",
    "    # Convert latent object headers to dtype specific strings for input to transformer\n",
    "    new_column_headers = []\n",
    "    for column_header in latent_object.columns:\n",
    "        # latent_header_prefix\n",
    "        new_column_header = latent_header_prefix+'_' + str(column_header)\n",
    "        new_column_headers.append(new_column_header)\n",
    "    latent_object.columns = new_column_headers\n",
    "    latent_object.insert(0, 'Cancer_type', cncr_lbls)\n",
    "    latent_object.insert(0, 'System', sys_lbls)\n",
    "    # break\n",
    "    latent_object.to_csv('../results/r72/tybalt/'+cancer+'_'+modality+'_'+\n",
    "                         systems+'.'+str(latent_dim)+'-ltnt-dim_'+\n",
    "                         str(epochs)+'-epchs.tsv', sep = '\\t')\n",
    "    plot_loss(loss_dict, cancer, modality, systems, latent_dim, train_file)\n",
    "    print('VAE done, latent object and loss plot written to disk')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057265e-2e79-404d-9c5b-080b54b043f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
